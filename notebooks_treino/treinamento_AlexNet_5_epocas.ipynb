{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtHw1O_kS7g6",
        "outputId": "f2c10b98-bb35-4011-9c77-78ec6fb33602"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'imagesoasis' dataset.\n",
            "Encontradas 86437 imagens\n",
            "Dispositivo: cuda\n",
            "Epoch 1/5\n",
            "Train Loss: 1.2248 | Val Loss: 0.9394\n",
            "Acc: 0.5158 | Prec: 0.3703 | Recall: 0.6444 | F1-macro: 0.3587\n",
            "------------------------------------------------------------\n",
            "Epoch 2/5\n",
            "Train Loss: 0.5861 | Val Loss: 0.3063\n",
            "Acc: 0.8567 | Prec: 0.7496 | Recall: 0.9083 | F1-macro: 0.8119\n",
            "------------------------------------------------------------\n",
            "Epoch 3/5\n",
            "Train Loss: 0.2318 | Val Loss: 0.1191\n",
            "Acc: 0.9452 | Prec: 0.9250 | Recall: 0.9658 | F1-macro: 0.9436\n",
            "------------------------------------------------------------\n",
            "Epoch 4/5\n",
            "Train Loss: 0.1171 | Val Loss: 0.0717\n",
            "Acc: 0.9555 | Prec: 0.9360 | Recall: 0.9781 | F1-macro: 0.9550\n",
            "------------------------------------------------------------\n",
            "Epoch 5/5\n",
            "Train Loss: 0.0608 | Val Loss: 0.0545\n",
            "Acc: 0.9637 | Prec: 0.9134 | Recall: 0.9847 | F1-macro: 0.9437\n",
            "------------------------------------------------------------\n",
            "Treinamento concluído!\n",
            "Métricas salvas em: alexnet_metrics.csv\n",
            "Matriz de Confusão:\n",
            " [[12736   249   333     0]\n",
            " [   20  2834    22     0]\n",
            " [    0     3   994     0]\n",
            " [    0     0     0    97]]\n",
            "Matriz de confusão salva em alexnet_confusion_matrix.npy\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import polars as pl\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ============================================================\n",
        "# Download do dataset OASIS via kagglehub\n",
        "# ============================================================\n",
        "path = kagglehub.dataset_download(\"ninadaithal/imagesoasis\")\n",
        "\n",
        "# Converter dataset de imagens em DataFrame Polars para EDA\n",
        "data_path = Path(path) / \"Data\"\n",
        "\n",
        "# Coletar paths das imagens usando Polars\n",
        "image_paths = []\n",
        "for p in data_path.rglob('*.*'):\n",
        "    if p.is_file():\n",
        "        parts = p.parts\n",
        "        if len(parts) >= 2:\n",
        "            class_name = parts[-2]  # pasta = classe\n",
        "            file_name = parts[-1]   # nome do arquivo\n",
        "            image_paths.append((class_name, file_name, str(p)))\n",
        "\n",
        "print(f\"Encontradas {len(image_paths)} imagens\")\n",
        "\n",
        "# Criar DataFrame Polars\n",
        "df = pl.DataFrame({\n",
        "    'class': [x[0] for x in image_paths],\n",
        "    'image': [x[1] for x in image_paths],\n",
        "    'path': [x[2] for x in image_paths]\n",
        "})\n",
        "\n",
        "# Salvar metadados em arquivo Parquet\n",
        "output_path = \"oasis_dataset_metadata.parquet\"\n",
        "df.write_parquet(output_path)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Configurações básicas\n",
        "# ============================================================\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Dispositivo: {device}\")\n",
        "\n",
        "# Transformações de pré-processamento\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((248, 496)),\n",
        "    transforms.CenterCrop((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Dataset personalizado\n",
        "class OASISDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "        self.class_to_idx = {\n",
        "            'Non Demented': 0,\n",
        "            'Very mild Dementia': 1,\n",
        "            'Mild Dementia': 2,\n",
        "            'Moderate Dementia': 3\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.row(idx)\n",
        "        img_path = row[2]\n",
        "        class_name = row[0]\n",
        "\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        label = self.class_to_idx[class_name]\n",
        "        return image, label\n",
        "\n",
        "# Carregar metadados\n",
        "df = pl.read_parquet(\"oasis_dataset_metadata.parquet\")\n",
        "dataset = OASISDataset(df, transform=transform)\n",
        "\n",
        "# Split treino/validação\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Modelo AlexNet (torchvision)\n",
        "# ============================================================\n",
        "model = models.alexnet(weights=None)\n",
        "# Ajustar a última camada para 4 classes\n",
        "model.classifier[6] = nn.Linear(model.classifier[6].in_features, 4)\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss function com pesos (para classes desbalanceadas)\n",
        "class_weights = torch.tensor([0.3215, 1.5744, 4.3201, 44.2812], dtype=torch.float32).to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Treinamento\n",
        "# ============================================================\n",
        "num_epochs = 5\n",
        "metrics_history = []\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_start = time.time()\n",
        "\n",
        "    # --- Training ---\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "\n",
        "    # --- Validation ---\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Estatísticas\n",
        "    train_loss = train_loss / len(train_loader.dataset)\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    prec = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    rec = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "    epoch_time = time.time() - epoch_start\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "    print(f'Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n",
        "    print(f'Acc: {acc:.4f} | Prec: {prec:.4f} | Recall: {rec:.4f} | F1-macro: {f1:.4f}')\n",
        "    print('-' * 60)\n",
        "\n",
        "    # Guardar métricas\n",
        "    metrics_history.append({\n",
        "        \"epoch\": epoch+1,\n",
        "        \"train_loss\": train_loss,\n",
        "        \"val_loss\": val_loss,\n",
        "        \"accuracy\": acc,\n",
        "        \"precision_macro\": prec,\n",
        "        \"recall_macro\": rec,\n",
        "        \"f1_macro\": f1,\n",
        "        \"epoch_time_sec\": epoch_time\n",
        "    })\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "print(\"Treinamento concluído!\")\n",
        "\n",
        "# ============================================================\n",
        "# Salvar métricas em CSV\n",
        "# ============================================================\n",
        "metrics_df = pd.DataFrame(metrics_history)\n",
        "metrics_df.to_csv(\"alexnet_metrics.csv\", index=False)\n",
        "print(\"Métricas salvas em: alexnet_metrics.csv\")\n",
        "\n",
        "# --- Após o treino ou validação final ---\n",
        "model.eval()\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Calcular a matriz de confusão\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(\"Matriz de Confusão:\\n\", cm)\n",
        "\n",
        "# Salvar com numpy\n",
        "np.save(\"alexnet_confusion_matrix.npy\", cm)\n",
        "print(\"Matriz de confusão salva em alexnet_confusion_matrix.npy\")"
      ]
    }
  ]
}